# Cross-Validation As Our Evaluation Metrices
-Train_Test_Split Give Us A Better Estimated Accuracy Than Training And Testing With The Entire Dataset But Have A Draw Back
- The Draw-Back Is , It Give Us A High Variance Estimate Since Changing Which Observations Happen In To The Testing_Set Can Significantly Changes The Testing Accuracy.
- So These Can Be Solved K-Flod Cross Validation , Which Means Calculate Train_Test_Split K Times And Average Them.
-Used Cross Validation For Parameter-Tuning , Model Selection  And Feature Selection